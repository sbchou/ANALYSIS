{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline \n",
    "import time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import nltk \n",
    "from collections import Counter\n",
    "pandas.options.display.max_colwidth = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study 1: Favor = Likert 3, Trust = Likert 5\n",
    "Study 2: Fair = Likert 5, Trust = Likert 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 720\n",
      "NULLS 0\n",
      "1280\n",
      "NULLS 2\n",
      "total annotations 2000\n",
      "total stories 128\n"
     ]
    }
   ],
   "source": [
    "# lump together all data\n",
    "results_1 = pandas.DataFrame.from_csv('../SURVEY/RESULTS/DATA/flattened_all_with_text.csv', encoding='utf8') \n",
    "print len(results_1)\n",
    "print \"NULLS\", results_1.trust.isnull().sum()\n",
    "results_2 = pandas.DataFrame.from_csv('../STUDY2/DATA/all_results/flattened_title_text.csv',encoding='utf8')\n",
    "print len(results_2)\n",
    "print \"NULLS\", results_2.trust.isnull().sum()\n",
    "all_df = pandas.concat([results_1, results_2])\n",
    "print \"total annotations\", len(all_df)\n",
    "print \"total stories\", len(all_df.title.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_to_last = {'Bernie Sanders':'sanders', 'Donald Trump':'trump', \n",
    "                'Hillary Clinton':'clinton', 'Ted Cruz':'cruz'}\n",
    "all_df['candidate'] = all_df.candidate.apply(lambda row: name_to_last[row] if row in name_to_last.keys() else row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMNS:\n",
      "age\tbody\tcandidate\tfair\tfavor\tflesch\tgender\tgunning_fog\tis_complex\torg\tparty\treadability\tsource\tstate\ttitle\ttopic\ttrust\turl\tvoting_for\n",
      "TOTAL ANNOTATIONS: 2000\n",
      "TOTAL NUMBER OF STORIES: 128\n",
      "TOTAL NUMBER PER CANDIDATE:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "candidate\n",
       "clinton    500\n",
       "cruz       500\n",
       "sanders    500\n",
       "trump      500\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"COLUMNS:\"\n",
    "print \"\\t\".join(list(all_df.columns))\n",
    "print \"TOTAL ANNOTATIONS:\", len(all_df)\n",
    "print \"TOTAL NUMBER OF STORIES:\", len(set(all_df.title))\n",
    "print \"TOTAL NUMBER PER CANDIDATE:\"\n",
    "all_df.groupby('candidate').title.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now let's calculate cumsum scores for fairness, trust, favor\n",
    "# so you end up with rows like:\n",
    "# title etc etc fair trust \n",
    "# one row per story.\n",
    "# also you can only do trust analysis since you have for all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hmmm....\n",
      "uniq titles 128\n",
      "uniq text 156\n",
      "uniq url 117\n"
     ]
    }
   ],
   "source": [
    "print \"hmmm....\"\n",
    "print 'uniq titles', all_df.title.nunique()\n",
    "print 'uniq text', all_df.body.nunique()\n",
    "print 'uniq url', all_df.url.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157\n"
     ]
    }
   ],
   "source": [
    "df = pandas.DataFrame(all_df.groupby(['title','body'], as_index=False).trust.mean())\n",
    "print len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Note: URLS missing from the AP stories in study 2.\n",
    "all_df[['title','url']].drop_duplicates('title').to_csv('DATA/title_url_only.csv', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now N Gram time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mutualInformation\n",
    "import wordportrait\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\"\"\"\n",
    "wordportrait.miportrait(\n",
    " Inputs:\n",
    "    userstat - dictionary of counts of words in tweets of target user (or group)\n",
    "    jointstat - dictionary of counts of words in everyone tweets\n",
    "    verbose - if True, adds frequencies and counts to the output (useful for debugging)\n",
    "    \n",
    "    Returns:\n",
    "        - The list of pairs (word, mutual information) if verbose = False\n",
    "        - The list of tuples (word, frequency by user, frequency by everyone else, count by user, count by everyone else, mutual information) if verbose = True\n",
    "   \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove stopwords  \n",
    "df['tokens'] = df.body.apply(lambda row: nltk.word_tokenize(row))\n",
    "punct = [x for x in string.punctuation]\n",
    "skip = stopwords.words('english') + punct + [\"''\", '``',\"'s\",\"--\"]\n",
    "df['tokens'] = df.tokens.apply(lambda row: [word for word in row if word not in skip])\n",
    "#filtered_words = [word for word in word_list if word not in stopwords.words('english')]\n",
    "df['word_count'] = df.tokens.apply(lambda row: Counter(row))\n",
    "all_counts = df.word_count.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.sort_values('trust', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "low = df[df.trust <= 0]\n",
    "hi = df[df.trust > 1]\n",
    "print len(low)\n",
    "print len(hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "low.title.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hi.title.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "low_counts = low.word_count.sum()\n",
    "hi_counts = hi.word_count.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "low_miportrait = wordportrait.miportrait(low_counts, all_counts)\n",
    "sorted(low_miportrait, key=lambda x: x[1])[20:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hi_miportrait = wordportrait.miportrait(hi_counts, all_counts)\n",
    "sorted(hi_miportrait, key=lambda x: x[1])[20:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_df[all_df.title=='Donald Trump, Despite Impieties, Wins Hearts of Evangelical Voters'].trust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
